{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vertex Smoothing\n",
    "\n",
    "Smoothing out or smoothing a vertex ***w*** with regards to the pair of edges (e1, e2) incident on ***w***, removes both edges containing ***w*** and replaces (e1, e2) with a new edge that connects the other endpoints of the pair.\n",
    "\n",
    "For example, the simple connected graph with two edges, e1 {u,w} and e2 {w,v}:\n",
    "![alt text](https://upload.wikimedia.org/wikipedia/commons/6/6f/Graph_subdivision_step2.svg \"Graph 1\")\n",
    "\n",
    "has a vertex (namely w) that can be smoothed away, resulting in:\n",
    "![alt text](https://upload.wikimedia.org/wikipedia/commons/1/15/Graph_subdivision_step1.svg \"Graph 1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphy.smoothing.vertexsmoothing import vertex_smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dwinSYBfkmi4"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222
    },
    "colab_type": "code",
    "id": "wleyVpxMkpUR",
    "outputId": "45e2a9a7-1d99-4cfe-b6d8-d31a7979c4a0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DAT17805.replynet.prv:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x19173f1ab00>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J1STiXwxQo5l"
   },
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dz-I1fqyWEG4"
   },
   "outputs": [],
   "source": [
    "# Utils functions ============================\n",
    "# TUPLE\n",
    "\n",
    "def source_getter_tuple(x):\n",
    "    return x[0]\n",
    "\n",
    "def target_getter_tuple(x):\n",
    "    return x[2]\n",
    "\n",
    "def link_getter_tuple(x):\n",
    "    return x[1]\n",
    "\n",
    "def obj_creator_tuple(s, l, t):\n",
    "    return (s, l, t)\n",
    "\n",
    "\n",
    "# DICT\n",
    "def source_getter_dict(x):\n",
    "    return x['SOURCE']\n",
    "\n",
    "def target_getter_dict(x):\n",
    "    return x['TARGET']\n",
    "\n",
    "def link_getter_dict(x):\n",
    "    return x['LINK']\n",
    "\n",
    "def obj_creator_dict(s, l, t):\n",
    "    return {'SOURCE': s, 'LINK': l, 'TARGET': t}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some example of usage..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 271
    },
    "colab_type": "code",
    "id": "LxMVWN-ub42i",
    "outputId": "5b5f6456-a706-46b9-e19e-3942d53b01a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TUPLE =================================================\n",
      "from\n",
      "to\n",
      "transform\n",
      "('sss', 'new_link', 'ttt')\n",
      "DICT ==================================================\n",
      "from\n",
      "to\n",
      "transform\n",
      "{'SOURCE': 'sss', 'LINK': 'new_link', 'TARGET': 'ttt'}\n"
     ]
    }
   ],
   "source": [
    "tup = ('from', 'transform', 'to')\n",
    "diz = {'SOURCE': 'from', 'LINK': 'transform', 'TARGET': 'to'}\n",
    "\n",
    "print(\"TUPLE =================================================\")\n",
    "print(source_getter_tuple(tup))\n",
    "print(target_getter_tuple(tup))\n",
    "print(link_getter_tuple(tup))\n",
    "print(obj_creator_tuple('sss', 'new_link', 'ttt'))\n",
    "print(\"DICT ==================================================\")\n",
    "print(source_getter_dict(diz))\n",
    "print(target_getter_dict(diz))\n",
    "print(link_getter_dict(diz))\n",
    "print(obj_creator_dict('sss', 'new_link', 'ttt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QaxJ73nKQiDY"
   },
   "source": [
    "## First trivial example\n",
    "\n",
    "Let's try a trivial example.\n",
    "\n",
    "we have the following links:\n",
    "\n",
    "    T_ORIGINAL_DATA -> V_DATA -> T_DATA_WORK -> T_DATA_FINAL\n",
    "\n",
    "and we want to end up with:\n",
    "    \n",
    "    T_ORIGINAL_DATA -> T_DATA_FINAL.\n",
    "\n",
    "We have to remove the two vertices in the middle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "colab_type": "code",
    "id": "eNWPE0mskpwp",
    "outputId": "7e981dab-5abf-4e89-fd96-513e758030cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|           ITEM|\n",
      "+---------------+\n",
      "|T_ORIGINAL_DATA|\n",
      "|         V_DATA|\n",
      "|    T_DATA_WORK|\n",
      "|   T_DATA_FINAL|\n",
      "+---------------+\n",
      "\n",
      "+---------------+----+------------+\n",
      "|         SOURCE|LINK|      TARGET|\n",
      "+---------------+----+------------+\n",
      "|T_ORIGINAL_DATA|  pt|      V_DATA|\n",
      "|         V_DATA|  si| T_DATA_WORK|\n",
      "|    T_DATA_WORK|  pt|T_DATA_FINAL|\n",
      "+---------------+----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# T_ORIGINAL_TABLE -> V_TABLE -> T_TABLE_WORK -> T_TABLE_FINAL\n",
    "# should become\n",
    "# T_ORIGINAL_TABLE -> T_TABLE_FINAL\n",
    "\n",
    "vertices_list = [\n",
    "    ('T_ORIGINAL_DATA',),\n",
    "    ('V_DATA',),\n",
    "    ('T_DATA_WORK',),\n",
    "    ('T_DATA_FINAL',)\n",
    "]\n",
    "\n",
    "links_list = [\n",
    "    ('T_ORIGINAL_DATA', 'pt', 'V_DATA'),\n",
    "    ('V_DATA', 'si', 'T_DATA_WORK'),\n",
    "    ('T_DATA_WORK', 'pt', 'T_DATA_FINAL')\n",
    "]\n",
    "\n",
    "vertices_df = spark.createDataFrame(vertices_list, ['ITEM'])\n",
    "links_df = spark.createDataFrame(links_list, ['SOURCE', 'LINK', 'TARGET'])\n",
    "\n",
    "vertices_df.show()\n",
    "links_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pZn2zsDfJwUF"
   },
   "source": [
    "### RDD as the collection data model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 144
    },
    "colab_type": "code",
    "id": "cy-A_xDNmqJF",
    "outputId": "449f2431-3349-4409-c264-3bdcad1cdfe1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RDD -> Links cleaned: [{'SOURCE': 'T_ORIGINAL_DATA', 'LINK': 'pt-si-pt', 'TARGET': 'T_DATA_FINAL'}]\n"
     ]
    }
   ],
   "source": [
    "vertices_rdd = vertices_df.rdd.map(lambda x: x.asDict())\n",
    "links_rdd = links_df.rdd.map(lambda x: x.asDict())\n",
    "\n",
    "vertices_to_remove = (vertices_rdd\n",
    "                      .map(lambda x: x['ITEM'])\n",
    "                      .filter(lambda x: x.startswith('V') or x.rfind('WORK') != -1)\n",
    "                      .collect()\n",
    "                      )\n",
    "vertices_cleaned_rdd = vertices_rdd.filter(lambda x: x['ITEM'] not in vertices_to_remove)\n",
    "\n",
    "links_cleaned_rdd = vertex_smoothing(\n",
    "    links_rdd.repartition(1), vertices_to_remove, source_getter_dict, target_getter_dict,\n",
    "    link_getter_dict, obj_creator_dict\n",
    ")\n",
    "print(\"RDD -> Links cleaned:\", links_cleaned_rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1761
    },
    "colab_type": "code",
    "id": "wFFxwcc9PJBC",
    "outputId": "819b7167-b844-494e-e239-f0fffd714f0f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6) UnionRDD[42] at union at NativeMethodAccessorImpl.java:0 []\n",
      " |  PythonRDD[40] at RDD at PythonRDD.scala:49 []\n",
      " |  UnionRDD[36] at union at NativeMethodAccessorImpl.java:0 []\n",
      " |  PythonRDD[34] at RDD at PythonRDD.scala:49 []\n",
      " |  MapPartitionsRDD[30] at coalesce at NativeMethodAccessorImpl.java:0 []\n",
      " |  CoalescedRDD[29] at coalesce at NativeMethodAccessorImpl.java:0 []\n",
      " |  ShuffledRDD[28] at coalesce at NativeMethodAccessorImpl.java:0 []\n",
      " +-(4) MapPartitionsRDD[27] at coalesce at NativeMethodAccessorImpl.java:0 []\n",
      "    |  PythonRDD[26] at RDD at PythonRDD.scala:49 []\n",
      "    |  MapPartitionsRDD[23] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "    |  MapPartitionsRDD[22] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "    |  MapPartitionsRDD[21] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "    |  MapPartitionsRDD[9] at applySchemaToPythonRDD at NativeMethodAccessorImpl.java:0 []\n",
      "    |  MapPartitionsRDD[8] at map at SerDeUtil.scala:137 []\n",
      "    |  MapPartitionsRDD[7] at mapPartitions at SerDeUtil.scala:184 []\n",
      "    |  PythonRDD[6] at RDD at PythonRDD.scala:49 []\n",
      "    |  ParallelCollectionRDD[5] at parallelize at PythonRDD.scala:184 []\n",
      " |  PythonRDD[35] at RDD at PythonRDD.scala:49 []\n",
      " |  CartesianRDD[33] at cartesian at NativeMethodAccessorImpl.java:0 []\n",
      " |  PythonRDD[31] at RDD at PythonRDD.scala:49 []\n",
      " |  MapPartitionsRDD[30] at coalesce at NativeMethodAccessorImpl.java:0 []\n",
      " |  CoalescedRDD[29] at coalesce at NativeMethodAccessorImpl.java:0 []\n",
      " |  ShuffledRDD[28] at coalesce at NativeMethodAccessorImpl.java:0 []\n",
      " +-(4) MapPartitionsRDD[27] at coalesce at NativeMethodAccessorImpl.java:0 []\n",
      "    |  PythonRDD[26] at RDD at PythonRDD.scala:49 []\n",
      "    |  MapPartitionsRDD[23] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "    |  MapPartitionsRDD[22] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "    |  MapPartitionsRDD[21] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "    |  MapPartitionsRDD[9] at applySchemaToPythonRDD at NativeMethodAccessorImpl.java:0 []\n",
      "    |  MapPartitionsRDD[8] at map at SerDeUtil.scala:137 []\n",
      "    |  MapPartitionsRDD[7] at mapPartitions at SerDeUtil.scala:184 []\n",
      "    |  PythonRDD[6] at RDD at PythonRDD.scala:49 []\n",
      "    |  ParallelCollectionRDD[5] at parallelize at PythonRDD.scala:184 []\n",
      " |  PythonRDD[32] at RDD at PythonRDD.scala:49 []\n",
      " |  MapPartitionsRDD[30] at coalesce at NativeMethodAccessorImpl.java:0 []\n",
      " |  CoalescedRDD[29] at coalesce at NativeMethodAccessorImpl.java:0 []\n",
      " |  ShuffledRDD[28] at coalesce at NativeMethodAccessorImpl.java:0 []\n",
      " +-(4) MapPartitionsRDD[27] at coalesce at NativeMethodAccessorImpl.java:0 []\n",
      "    |  PythonRDD[26] at RDD at PythonRDD.scala:49 []\n",
      "    |  MapPartitionsRDD[23] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "    |  MapPartitionsRDD[22] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "    |  MapPartitionsRDD[21] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "    |  MapPartitionsRDD[9] at applySchemaToPythonRDD at NativeMethodAccessorImpl.java:0 []\n",
      "    |  MapPartitionsRDD[8] at map at SerDeUtil.scala:137 []\n",
      "    |  MapPartitionsRDD[7] at mapPartitions at SerDeUtil.scala:184 []\n",
      "    |  PythonRDD[6] at RDD at PythonRDD.scala:49 []\n",
      "    |  ParallelCollectionRDD[5] at parallelize at PythonRDD.scala:184 []\n",
      " |  PythonRDD[41] at RDD at PythonRDD.scala:49 []\n",
      " |  CartesianRDD[39] at cartesian at NativeMethodAccessorImpl.java:0 []\n",
      " |  PythonRDD[37] at RDD at PythonRDD.scala:49 []\n",
      " |  UnionRDD[36] at union at NativeMethodAccessorImpl.java:0 []\n",
      " |  PythonRDD[34] at RDD at PythonRDD.scala:49 []\n",
      " |  MapPartitionsRDD[30] at coalesce at NativeMethodAccessorImpl.java:0 []\n",
      " |  CoalescedRDD[29] at coalesce at NativeMethodAccessorImpl.java:0 []\n",
      " |  ShuffledRDD[28] at coalesce at NativeMethodAccessorImpl.java:0 []\n",
      " +-(4) MapPartitionsRDD[27] at coalesce at NativeMethodAccessorImpl.java:0 []\n",
      "    |  PythonRDD[26] at RDD at PythonRDD.scala:49 []\n",
      "    |  MapPartitionsRDD[23] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "    |  MapPartitionsRDD[22] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "    |  MapPartitionsRDD[21] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "    |  MapPartitionsRDD[9] at applySchemaToPythonRDD at NativeMethodAccessorImpl.java:0 []\n",
      "    |  MapPartitionsRDD[8] at map at SerDeUtil.scala:137 []\n",
      "    |  MapPartitionsRDD[7] at mapPartitions at SerDeUtil.scala:184 []\n",
      "    |  PythonRDD[6] at RDD at PythonRDD.scala:49 []\n",
      "    |  ParallelCollectionRDD[5] at parallelize at PythonRDD.scala:184 []\n",
      " |  PythonRDD[35] at RDD at PythonRDD.scala:49 []\n",
      " |  CartesianRDD[33] at cartesian at NativeMethodAccessorImpl.java:0 []\n",
      " |  PythonRDD[31] at RDD at PythonRDD.scala:49 []\n",
      " |  MapPartitionsRDD[30] at coalesce at NativeMethodAccessorImpl.java:0 []\n",
      " |  CoalescedRDD[29] at coalesce at NativeMethodAccessorImpl.java:0 []\n",
      " |  ShuffledRDD[28] at coalesce at NativeMethodAccessorImpl.java:0 []\n",
      " +-(4) MapPartitionsRDD[27] at coalesce at NativeMethodAccessorImpl.java:0 []\n",
      "    |  PythonRDD[26] at RDD at PythonRDD.scala:49 []\n",
      "    |  MapPartitionsRDD[23] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "    |  MapPartitionsRDD[22] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "    |  MapPartitionsRDD[21] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "    |  MapPartitionsRDD[9] at applySchemaToPythonRDD at NativeMethodAccessorImpl.java:0 []\n",
      "    |  MapPartitionsRDD[8] at map at SerDeUtil.scala:137 []\n",
      "    |  MapPartitionsRDD[7] at mapPartitions at SerDeUtil.scala:184 []\n",
      "    |  PythonRDD[6] at RDD at PythonRDD.scala:49 []\n",
      "    |  ParallelCollectionRDD[5] at parallelize at PythonRDD.scala:184 []\n",
      " |  PythonRDD[32] at RDD at PythonRDD.scala:49 []\n",
      " |  MapPartitionsRDD[30] at coalesce at NativeMethodAccessorImpl.java:0 []\n",
      " |  CoalescedRDD[29] at coalesce at NativeMethodAccessorImpl.java:0 []\n",
      " |  ShuffledRDD[28] at coalesce at NativeMethodAccessorImpl.java:0 []\n",
      " +-(4) MapPartitionsRDD[27] at coalesce at NativeMethodAccessorImpl.java:0 []\n",
      "    |  PythonRDD[26] at RDD at PythonRDD.scala:49 []\n",
      "    |  MapPartitionsRDD[23] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "    |  MapPartitionsRDD[22] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "    |  MapPartitionsRDD[21] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "    |  MapPartitionsRDD[9] at applySchemaToPythonRDD at NativeMethodAccessorImpl.java:0 []\n",
      "    |  MapPartitionsRDD[8] at map at SerDeUtil.scala:137 []\n",
      "    |  MapPartitionsRDD[7] at mapPartitions at SerDeUtil.scala:184 []\n",
      "    |  PythonRDD[6] at RDD at PythonRDD.scala:49 []\n",
      "    |  ParallelCollectionRDD[5] at parallelize at PythonRDD.scala:184 []\n",
      " |  PythonRDD[38] at RDD at PythonRDD.scala:49 []\n",
      " |  UnionRDD[36] at union at NativeMethodAccessorImpl.java:0 []\n",
      " |  PythonRDD[34] at RDD at PythonRDD.scala:49 []\n",
      " |  MapPartitionsRDD[30] at coalesce at NativeMethodAccessorImpl.java:0 []\n",
      " |  CoalescedRDD[29] at coalesce at NativeMethodAccessorImpl.java:0 []\n",
      " |  ShuffledRDD[28] at coalesce at NativeMethodAccessorImpl.java:0 []\n",
      " +-(4) MapPartitionsRDD[27] at coalesce at NativeMethodAccessorImpl.java:0 []\n",
      "    |  PythonRDD[26] at RDD at PythonRDD.scala:49 []\n",
      "    |  MapPartitionsRDD[23] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "    |  MapPartitionsRDD[22] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "    |  MapPartitionsRDD[21] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "    |  MapPartitionsRDD[9] at applySchemaToPythonRDD at NativeMethodAccessorImpl.java:0 []\n",
      "    |  MapPartitionsRDD[8] at map at SerDeUtil.scala:137 []\n",
      "    |  MapPartitionsRDD[7] at mapPartitions at SerDeUtil.scala:184 []\n",
      "    |  PythonRDD[6] at RDD at PythonRDD.scala:49 []\n",
      "    |  ParallelCollectionRDD[5] at parallelize at PythonRDD.scala:184 []\n",
      " |  PythonRDD[35] at RDD at PythonRDD.scala:49 []\n",
      " |  CartesianRDD[33] at cartesian at NativeMethodAccessorImpl.java:0 []\n",
      " |  PythonRDD[31] at RDD at PythonRDD.scala:49 []\n",
      " |  MapPartitionsRDD[30] at coalesce at NativeMethodAccessorImpl.java:0 []\n",
      " |  CoalescedRDD[29] at coalesce at NativeMethodAccessorImpl.java:0 []\n",
      " |  ShuffledRDD[28] at coalesce at NativeMethodAccessorImpl.java:0 []\n",
      " +-(4) MapPartitionsRDD[27] at coalesce at NativeMethodAccessorImpl.java:0 []\n",
      "    |  PythonRDD[26] at RDD at PythonRDD.scala:49 []\n",
      "    |  MapPartitionsRDD[23] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "    |  MapPartitionsRDD[22] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "    |  MapPartitionsRDD[21] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "    |  MapPartitionsRDD[9] at applySchemaToPythonRDD at NativeMethodAccessorImpl.java:0 []\n",
      "    |  MapPartitionsRDD[8] at map at SerDeUtil.scala:137 []\n",
      "    |  MapPartitionsRDD[7] at mapPartitions at SerDeUtil.scala:184 []\n",
      "    |  PythonRDD[6] at RDD at PythonRDD.scala:49 []\n",
      "    |  ParallelCollectionRDD[5] at parallelize at PythonRDD.scala:184 []\n",
      " |  PythonRDD[32] at RDD at PythonRDD.scala:49 []\n",
      " |  MapPartitionsRDD[30] at coalesce at NativeMethodAccessorImpl.java:0 []\n",
      " |  CoalescedRDD[29] at coalesce at NativeMethodAccessorImpl.java:0 []\n",
      " |  ShuffledRDD[28] at coalesce at NativeMethodAccessorImpl.java:0 []\n",
      " +-(4) MapPartitionsRDD[27] at coalesce at NativeMethodAccessorImpl.java:0 []\n",
      "    |  PythonRDD[26] at RDD at PythonRDD.scala:49 []\n",
      "    |  MapPartitionsRDD[23] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "    |  MapPartitionsRDD[22] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "    |  MapPartitionsRDD[21] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      "    |  MapPartitionsRDD[9] at applySchemaToPythonRDD at NativeMethodAccessorImpl.java:0 []\n",
      "    |  MapPartitionsRDD[8] at map at SerDeUtil.scala:137 []\n",
      "    |  MapPartitionsRDD[7] at mapPartitions at SerDeUtil.scala:184 []\n",
      "    |  PythonRDD[6] at RDD at PythonRDD.scala:49 []\n",
      "    |  ParallelCollectionRDD[5] at parallelize at PythonRDD.scala:184 []\n"
     ]
    }
   ],
   "source": [
    "print(links_cleaned_rdd.toDebugString().decode('UTF-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "cqKSzD8vQ9_g",
    "outputId": "56c83967-c549-4411-906c-23d251507aa4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links_cleaned_rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ytK1gS7q2A0U"
   },
   "source": [
    "### LIST as the collection data model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KsQguLvB2ACS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIST -> Links cleaned: [('T_ORIGINAL_DATA', 'pt-si-pt', 'T_DATA_FINAL')]\n"
     ]
    }
   ],
   "source": [
    "vertices_to_remove = filter(lambda x: x.startswith('V') or x.rfind('WORK') != -1,\n",
    "                            map(lambda x: x[0], vertices_list))\n",
    "vertices_cleaned_list = filter(lambda x: x[0] not in vertices_to_remove, vertices_list)\n",
    "\n",
    "links_cleaned_list = vertex_smoothing(\n",
    "    links_list, vertices_to_remove, source_getter_tuple, target_getter_tuple,\n",
    "    link_getter_tuple, obj_creator_tuple\n",
    ")\n",
    "print(\"LIST -> Links cleaned:\", links_cleaned_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SYg-UkvQRjds"
   },
   "source": [
    "## Second (not trivial) example\n",
    "\n",
    "Let's try a less trivial example.\n",
    "\n",
    "We have the following links:\n",
    "\n",
    "     T_ORIGINAL_TABLE_1 -\\                            /-> T_TABLE_FINAL_1 \n",
    "                          -> V_TABLE -> T_TABLE_WORK -\n",
    "     T_ORIGINAL_TABLE_2 -/                            \\-> T_TABLE_FINAL_2\n",
    "\n",
    "and we want to end up with:\n",
    "\n",
    "     T_ORIGINAL_TABLE_1 -\\ /-> T_TABLE_FINAL_1 \n",
    "                          X\n",
    "     T_ORIGINAL_TABLE_2 -/ \\-> T_TABLE_FINAL_2\n",
    "\n",
    "We have to remove the two vertices in the middle, and build more complex links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "colab_type": "code",
    "id": "Iar7UtvNRQ14",
    "outputId": "a2771326-c43f-42c5-dd2d-f46e93109336"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|              ITEM|\n",
      "+------------------+\n",
      "|T_ORIGINAL_TABLE_1|\n",
      "|T_ORIGINAL_TABLE_2|\n",
      "|           V_TABLE|\n",
      "|      T_TABLE_WORK|\n",
      "|   T_TABLE_FINAL_1|\n",
      "|   T_TABLE_FINAL_2|\n",
      "+------------------+\n",
      "\n",
      "+------------------+----+---------------+\n",
      "|            SOURCE|LINK|         TARGET|\n",
      "+------------------+----+---------------+\n",
      "|T_ORIGINAL_TABLE_1|  mi|        V_TABLE|\n",
      "|T_ORIGINAL_TABLE_2|  mi|        V_TABLE|\n",
      "|           V_TABLE|  pt|   T_TABLE_WORK|\n",
      "|      T_TABLE_WORK|  si|T_TABLE_FINAL_1|\n",
      "|      T_TABLE_WORK|  si|T_TABLE_FINAL_2|\n",
      "+------------------+----+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# T_ORIGINAL_TABLE_1 -\\                            /-> T_TABLE_FINAL_1 \n",
    "#                      -> V_TABLE -> T_TABLE_WORK -\n",
    "# T_ORIGINAL_TABLE_2 -/                            \\-> T_TABLE_FINAL_2\n",
    "#\n",
    "# should become\n",
    "#\n",
    "# T_ORIGINAL_TABLE_1 -\\ /-> T_TABLE_FINAL_1 \n",
    "#                      X\n",
    "# T_ORIGINAL_TABLE_2 -/ \\-> T_TABLE_FINAL_2\n",
    "\n",
    "\n",
    "vertices_list = [\n",
    "    (\"T_ORIGINAL_TABLE_1\",),\n",
    "    (\"T_ORIGINAL_TABLE_2\",),\n",
    "    (\"V_TABLE\",),\n",
    "    (\"T_TABLE_WORK\",),\n",
    "    (\"T_TABLE_FINAL_1\",),\n",
    "    (\"T_TABLE_FINAL_2\",)\n",
    "]\n",
    "\n",
    "links_list = [\n",
    "    ('T_ORIGINAL_TABLE_1', 'mi', 'V_TABLE'),\n",
    "    ('T_ORIGINAL_TABLE_2', 'mi', 'V_TABLE'),\n",
    "    ('V_TABLE', 'pt', 'T_TABLE_WORK'),\n",
    "    ('T_TABLE_WORK', 'si', 'T_TABLE_FINAL_1'),\n",
    "    ('T_TABLE_WORK', 'si', 'T_TABLE_FINAL_2')\n",
    "]\n",
    "\n",
    "vertices_df = spark.createDataFrame(vertices_list, [\"ITEM\"])\n",
    "links_df = spark.createDataFrame(links_list, [\"SOURCE\", \"LINK\", \"TARGET\"])\n",
    "\n",
    "vertices_df.show()\n",
    "links_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3PUDxTvASa7_"
   },
   "source": [
    "### RDD as the collection data model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "colab_type": "code",
    "id": "Y_7dPyD9SW1h",
    "outputId": "568c5af9-a0b3-421c-d5d5-093db735beee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RDD -> Links cleaned: [{'SOURCE': 'T_ORIGINAL_TABLE_1', 'LINK': 'mi-pt-si', 'TARGET': 'T_TABLE_FINAL_1'}, {'SOURCE': 'T_ORIGINAL_TABLE_1', 'LINK': 'mi-pt-si', 'TARGET': 'T_TABLE_FINAL_2'}, {'SOURCE': 'T_ORIGINAL_TABLE_2', 'LINK': 'mi-pt-si', 'TARGET': 'T_TABLE_FINAL_1'}, {'SOURCE': 'T_ORIGINAL_TABLE_2', 'LINK': 'mi-pt-si', 'TARGET': 'T_TABLE_FINAL_2'}]\n"
     ]
    }
   ],
   "source": [
    "vertices_rdd = vertices_df.rdd.map(lambda x: x.asDict())\n",
    "links_rdd = links_df.rdd.map(lambda x: x.asDict())\n",
    "\n",
    "vertices_to_remove = (vertices_rdd\n",
    "                      .map(lambda x: x['ITEM'])\n",
    "                      .filter(lambda x: x.startswith('V') or x.rfind('WORK') != -1)\n",
    "                      .collect()\n",
    "                      )\n",
    "vertices_cleaned_rdd = vertices_rdd.filter(lambda x: x['ITEM'] not in vertices_to_remove)\n",
    "\n",
    "links_cleaned_rdd = vertex_smoothing(\n",
    "    links_rdd.repartition(1), vertices_to_remove, source_getter_dict, target_getter_dict,\n",
    "    link_getter_dict, obj_creator_dict\n",
    ")\n",
    "print(\"RDD -> Links cleaned:\", links_cleaned_rdd.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IxtRQ5T_StMi"
   },
   "source": [
    "### LIST as the collection data model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cn419bfPSovJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIST -> Links cleaned: [('T_ORIGINAL_TABLE_1', 'mi-pt-si', 'T_TABLE_FINAL_1'), ('T_ORIGINAL_TABLE_1', 'mi-pt-si', 'T_TABLE_FINAL_2'), ('T_ORIGINAL_TABLE_2', 'mi-pt-si', 'T_TABLE_FINAL_1'), ('T_ORIGINAL_TABLE_2', 'mi-pt-si', 'T_TABLE_FINAL_2')]\n"
     ]
    }
   ],
   "source": [
    "vertices_to_remove = filter(lambda x: x.startswith('V') or x.rfind('WORK') != -1,\n",
    "                            map(lambda x: x[0], vertices_list))\n",
    "vertices_cleaned_list = filter(lambda x: x[0] not in vertices_to_remove, vertices_list)\n",
    "\n",
    "links_cleaned_list = vertex_smoothing(\n",
    "    links_list, vertices_to_remove, source_getter_tuple, target_getter_tuple,\n",
    "    link_getter_tuple, obj_creator_tuple\n",
    ")\n",
    "print(\"LIST -> Links cleaned:\", links_cleaned_list)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Bypassing nodes in a graph with Spark.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
